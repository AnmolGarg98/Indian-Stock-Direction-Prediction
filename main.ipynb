{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_model import TransformerModel\n",
    "from dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bollinger_bands(data, window=10, num_of_std=2):\n",
    "    \"\"\"Calculate Bollinger Bands\"\"\"\n",
    "    rolling_mean = data.rolling(window=window).mean()\n",
    "    rolling_std = data.rolling(window=window).std()\n",
    "    upper_band = rolling_mean + (rolling_std * num_of_std)\n",
    "    lower_band = rolling_mean - (rolling_std * num_of_std)\n",
    "    return upper_band, lower_band\n",
    "\n",
    "def calculate_rsi(data, window=10):\n",
    "    \"\"\"Calculate Relative Strength Index\"\"\"\n",
    "    delta = data.diff()\n",
    "    gain = delta.clip(lower=0)\n",
    "    loss = -delta.clip(upper=0)\n",
    "    avg_gain = gain.rolling(window=window, min_periods=1).mean()\n",
    "    avg_loss = loss.rolling(window=window, min_periods=1).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "def calculate_roc(data, periods=10):\n",
    "    \"\"\"Calculate Rate of Change.\"\"\"\n",
    "    roc = ((data - data.shift(periods)) / data.shift(periods)) * 100\n",
    "    return roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['TCS', 'WIPRO', 'HCLTECH', 'INFY', 'LTIM', 'TECHM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "ticker_data_frames = []\n",
    "stats = {}\n",
    "for ticker in tickers:\n",
    "    ticker = ticker + '.NS'\n",
    "    # Download historical data for the ticker\n",
    "    data = yf.download(ticker, period=\"5y\", interval=\"1d\")\n",
    "\n",
    "    # Calculate the daily percentage change\n",
    "    close = data['Close']\n",
    "    upper, lower = calculate_bollinger_bands(close, window=14, num_of_std=2)\n",
    "    width = upper - lower\n",
    "    rsi = calculate_rsi(close, window=14)\n",
    "    roc = calculate_roc(close, periods=14)\n",
    "    volume = data['Volume']\n",
    "    diff = data['Close'].diff(1)\n",
    "    percent_change_close = data['Close'].pct_change() * 100\n",
    "\n",
    "    # Create a DataFrame for the current ticker and append it to the list\n",
    "    ticker_df = pd.DataFrame({\n",
    "        ticker+'_close': close,\n",
    "        ticker+'_width': width,\n",
    "        ticker+'_rsi': rsi,\n",
    "        ticker+'_roc': roc,\n",
    "        ticker+'_volume': volume,\n",
    "        ticker+'_diff': diff,\n",
    "        ticker+'_percent_change_close': percent_change_close,\n",
    "    })\n",
    "    \n",
    "    MEAN = ticker_df.mean()\n",
    "    STD = ticker_df.std()\n",
    "\n",
    "    # Keep track of mean and std\n",
    "    for column in MEAN.index:\n",
    "      stats[f\"{column}_mean\"] = MEAN[column]\n",
    "      stats[f\"{column}_std\"] = STD[column]\n",
    "    \n",
    "    # # Normalize the training features\n",
    "    # ticker_df = (ticker_df - MEAN) / STD\n",
    "\n",
    "    ticker_data_frames.append(ticker_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TCS.NS_close_mean</th>\n",
       "      <th>TCS.NS_close_std</th>\n",
       "      <th>TCS.NS_width_mean</th>\n",
       "      <th>TCS.NS_width_std</th>\n",
       "      <th>TCS.NS_rsi_mean</th>\n",
       "      <th>TCS.NS_rsi_std</th>\n",
       "      <th>TCS.NS_roc_mean</th>\n",
       "      <th>TCS.NS_roc_std</th>\n",
       "      <th>TCS.NS_volume_mean</th>\n",
       "      <th>TCS.NS_volume_std</th>\n",
       "      <th>...</th>\n",
       "      <th>TECHM.NS_rsi_mean</th>\n",
       "      <th>TECHM.NS_rsi_std</th>\n",
       "      <th>TECHM.NS_roc_mean</th>\n",
       "      <th>TECHM.NS_roc_std</th>\n",
       "      <th>TECHM.NS_volume_mean</th>\n",
       "      <th>TECHM.NS_volume_std</th>\n",
       "      <th>TECHM.NS_diff_mean</th>\n",
       "      <th>TECHM.NS_diff_std</th>\n",
       "      <th>TECHM.NS_percent_change_close_mean</th>\n",
       "      <th>TECHM.NS_percent_change_close_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3103.656071</td>\n",
       "      <td>635.026142</td>\n",
       "      <td>246.54054</td>\n",
       "      <td>116.087634</td>\n",
       "      <td>53.164785</td>\n",
       "      <td>16.328442</td>\n",
       "      <td>0.86858</td>\n",
       "      <td>5.265469</td>\n",
       "      <td>2.775387e+06</td>\n",
       "      <td>1.723884e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>53.443288</td>\n",
       "      <td>16.745527</td>\n",
       "      <td>1.206234</td>\n",
       "      <td>7.096912</td>\n",
       "      <td>3.233784e+06</td>\n",
       "      <td>2.216003e+06</td>\n",
       "      <td>0.661548</td>\n",
       "      <td>20.249652</td>\n",
       "      <td>0.083426</td>\n",
       "      <td>1.95063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TCS.NS_close_mean  TCS.NS_close_std  TCS.NS_width_mean  TCS.NS_width_std  \\\n",
       "0        3103.656071        635.026142          246.54054        116.087634   \n",
       "\n",
       "   TCS.NS_rsi_mean  TCS.NS_rsi_std  TCS.NS_roc_mean  TCS.NS_roc_std  \\\n",
       "0        53.164785       16.328442          0.86858        5.265469   \n",
       "\n",
       "   TCS.NS_volume_mean  TCS.NS_volume_std  ...  TECHM.NS_rsi_mean  \\\n",
       "0        2.775387e+06       1.723884e+06  ...          53.443288   \n",
       "\n",
       "   TECHM.NS_rsi_std  TECHM.NS_roc_mean  TECHM.NS_roc_std  \\\n",
       "0         16.745527           1.206234          7.096912   \n",
       "\n",
       "   TECHM.NS_volume_mean  TECHM.NS_volume_std  TECHM.NS_diff_mean  \\\n",
       "0          3.233784e+06         2.216003e+06            0.661548   \n",
       "\n",
       "   TECHM.NS_diff_std  TECHM.NS_percent_change_close_mean  \\\n",
       "0          20.249652                            0.083426   \n",
       "\n",
       "   TECHM.NS_percent_change_close_std  \n",
       "0                            1.95063  \n",
       "\n",
       "[1 rows x 84 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the dictionary containing feature statistics to a DataFrame for easier access\n",
    "stats = pd.DataFrame([stats], index=[0])\n",
    "\n",
    "# Display the DataFrame to verify its structure\n",
    "stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TCS.NS_close</th>\n",
       "      <th>TCS.NS_width</th>\n",
       "      <th>TCS.NS_rsi</th>\n",
       "      <th>TCS.NS_roc</th>\n",
       "      <th>TCS.NS_volume</th>\n",
       "      <th>TCS.NS_diff</th>\n",
       "      <th>TCS.NS_percent_change_close</th>\n",
       "      <th>WIPRO.NS_close</th>\n",
       "      <th>WIPRO.NS_width</th>\n",
       "      <th>WIPRO.NS_rsi</th>\n",
       "      <th>...</th>\n",
       "      <th>LTIM.NS_volume</th>\n",
       "      <th>LTIM.NS_diff</th>\n",
       "      <th>LTIM.NS_percent_change_close</th>\n",
       "      <th>TECHM.NS_close</th>\n",
       "      <th>TECHM.NS_width</th>\n",
       "      <th>TECHM.NS_rsi</th>\n",
       "      <th>TECHM.NS_roc</th>\n",
       "      <th>TECHM.NS_volume</th>\n",
       "      <th>TECHM.NS_diff</th>\n",
       "      <th>TECHM.NS_percent_change_close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-08-08</th>\n",
       "      <td>2258.100098</td>\n",
       "      <td>221.628052</td>\n",
       "      <td>74.364528</td>\n",
       "      <td>8.721931</td>\n",
       "      <td>2073298</td>\n",
       "      <td>44.650146</td>\n",
       "      <td>2.017220</td>\n",
       "      <td>265.75</td>\n",
       "      <td>10.331389</td>\n",
       "      <td>51.653524</td>\n",
       "      <td>...</td>\n",
       "      <td>49320</td>\n",
       "      <td>22.950073</td>\n",
       "      <td>1.434066</td>\n",
       "      <td>680.200012</td>\n",
       "      <td>69.044901</td>\n",
       "      <td>52.350538</td>\n",
       "      <td>0.762910</td>\n",
       "      <td>2708834</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>0.852547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-09</th>\n",
       "      <td>2246.250000</td>\n",
       "      <td>223.433874</td>\n",
       "      <td>69.442483</td>\n",
       "      <td>6.462397</td>\n",
       "      <td>1744550</td>\n",
       "      <td>-11.850098</td>\n",
       "      <td>-0.524782</td>\n",
       "      <td>263.50</td>\n",
       "      <td>10.263133</td>\n",
       "      <td>48.082615</td>\n",
       "      <td>...</td>\n",
       "      <td>156454</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>0.754636</td>\n",
       "      <td>663.349976</td>\n",
       "      <td>66.887992</td>\n",
       "      <td>46.512556</td>\n",
       "      <td>-1.279863</td>\n",
       "      <td>3743407</td>\n",
       "      <td>-16.850037</td>\n",
       "      <td>-2.477218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            TCS.NS_close  TCS.NS_width  TCS.NS_rsi  TCS.NS_roc  TCS.NS_volume  \\\n",
       "Date                                                                            \n",
       "2019-08-08   2258.100098    221.628052   74.364528    8.721931        2073298   \n",
       "2019-08-09   2246.250000    223.433874   69.442483    6.462397        1744550   \n",
       "\n",
       "            TCS.NS_diff  TCS.NS_percent_change_close  WIPRO.NS_close  \\\n",
       "Date                                                                   \n",
       "2019-08-08    44.650146                     2.017220          265.75   \n",
       "2019-08-09   -11.850098                    -0.524782          263.50   \n",
       "\n",
       "            WIPRO.NS_width  WIPRO.NS_rsi  ...  LTIM.NS_volume  LTIM.NS_diff  \\\n",
       "Date                                      ...                                 \n",
       "2019-08-08       10.331389     51.653524  ...           49320     22.950073   \n",
       "2019-08-09       10.263133     48.082615  ...          156454     12.250000   \n",
       "\n",
       "            LTIM.NS_percent_change_close  TECHM.NS_close  TECHM.NS_width  \\\n",
       "Date                                                                       \n",
       "2019-08-08                      1.434066      680.200012       69.044901   \n",
       "2019-08-09                      0.754636      663.349976       66.887992   \n",
       "\n",
       "            TECHM.NS_rsi  TECHM.NS_roc  TECHM.NS_volume  TECHM.NS_diff  \\\n",
       "Date                                                                     \n",
       "2019-08-08     52.350538      0.762910          2708834       5.750000   \n",
       "2019-08-09     46.512556     -1.279863          3743407     -16.850037   \n",
       "\n",
       "            TECHM.NS_percent_change_close  \n",
       "Date                                       \n",
       "2019-08-08                       0.852547  \n",
       "2019-08-09                      -2.477218  \n",
       "\n",
       "[2 rows x 42 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(ticker_data_frames, axis=1)\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* add date end\n",
    "* add time to sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LEN = 15  # 15 days of data\n",
    "BATCH_SIZE = 32\n",
    "dataset = Dataset(df,SEQUENCE_LEN)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "            train_set,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,num_workers=4,drop_last=True\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "            val_set,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,num_workers=4,drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_acc(seq,y_true, y_pred):\n",
    "    y_true_prev = seq[:,-1,0]\n",
    "    # print(y_true.shape,y_true_prev.shape,y_pred.shape)\n",
    "    true_change = y_true - y_true_prev  # Calculate true change\n",
    "    pred_change = y_pred.squeeze(1) - y_true_prev  # Calculate predicted change\n",
    "    # print(torch.sign(true_change), torch.sign(pred_change))\n",
    "    correct_direction = torch.eq(torch.sign(true_change), torch.sign(pred_change))  # Check if the signs match\n",
    "    # print(correct_direction)\n",
    "    return torch.mean(torch.tensor(correct_direction).float())  # Return the mean of correct directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "sequence_length = 12\n",
    "input_size = 42\n",
    "output_size = 1\n",
    "num_layers = 2\n",
    "d_model = 64\n",
    "nhead = 4\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instantiate the model, loss function and optimizer\n",
    "model = TransformerModel(input_size, output_size, d_model, nhead, num_layers)\n",
    "model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "100%|██████████| 60/60 [00:05<00:00, 10.29it/s]\n",
      "/tmp/ipykernel_1543307/3337551381.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.mean(torch.tensor(correct_direction).float())  # Return the mean of correct directions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:0 Train_loss:3.4817123413085938 Val_loss:2.5427749156951904 Dir Accuracy:f0.5166667103767395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:06<00:00,  9.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:1 Train_loss:3.365734338760376 Val_loss:2.5194661617279053 Dir Accuracy:f0.5083333849906921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:06<00:00,  9.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:2 Train_loss:3.3323707580566406 Val_loss:2.6366095542907715 Dir Accuracy:f0.5208333730697632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:06<00:00,  9.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:3 Train_loss:3.3230044841766357 Val_loss:2.5268192291259766 Dir Accuracy:f0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:4 Train_loss:3.321408748626709 Val_loss:2.491849422454834 Dir Accuracy:f0.5208333730697632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:06<00:00,  9.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:5 Train_loss:3.3293285369873047 Val_loss:2.7257843017578125 Dir Accuracy:f0.5166667103767395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:06<00:00,  9.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:6 Train_loss:3.3395516872406006 Val_loss:2.6564674377441406 Dir Accuracy:f0.5125000476837158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:7 Train_loss:3.319493532180786 Val_loss:2.5761024951934814 Dir Accuracy:f0.5125000476837158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:06<00:00,  9.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:8 Train_loss:3.3181588649749756 Val_loss:2.4835238456726074 Dir Accuracy:f0.5166667103767395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:06<00:00,  9.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:9 Train_loss:3.3212730884552 Val_loss:2.5131781101226807 Dir Accuracy:f0.5041667222976685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:06<00:00,  9.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:10 Train_loss:3.3368849754333496 Val_loss:2.5333151817321777 Dir Accuracy:f0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:06<00:00,  9.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:11 Train_loss:3.313323736190796 Val_loss:2.5141797065734863 Dir Accuracy:f0.5166667103767395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:12 Train_loss:3.3319783210754395 Val_loss:2.546980619430542 Dir Accuracy:f0.5125000476837158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:06<00:00,  9.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:13 Train_loss:3.2987492084503174 Val_loss:2.509134292602539 Dir Accuracy:f0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:14 Train_loss:3.3148839473724365 Val_loss:2.561096668243408 Dir Accuracy:f0.5166667103767395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:06<00:00,  9.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:15 Train_loss:3.31581974029541 Val_loss:2.4979751110076904 Dir Accuracy:f0.5291666984558105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:16 Train_loss:3.31976580619812 Val_loss:2.522981882095337 Dir Accuracy:f0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:06<00:00,  9.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:17 Train_loss:3.3082096576690674 Val_loss:2.5016725063323975 Dir Accuracy:f0.5208333730697632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:18 Train_loss:3.3003571033477783 Val_loss:2.554375648498535 Dir Accuracy:f0.5125000476837158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:06<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:19 Train_loss:3.2878901958465576 Val_loss:2.589150905609131 Dir Accuracy:f0.5166667103767395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:20 Train_loss:3.3260421752929688 Val_loss:2.5617897510528564 Dir Accuracy:f0.5125000476837158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:06<00:00,  9.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:21 Train_loss:3.30718994140625 Val_loss:2.541612148284912 Dir Accuracy:f0.5166667103767395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:06<00:00,  9.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:22 Train_loss:3.296342134475708 Val_loss:2.4876723289489746 Dir Accuracy:f0.5166667103767395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:06<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:23 Train_loss:3.2688722610473633 Val_loss:2.565500259399414 Dir Accuracy:f0.5125000476837158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:06<00:00,  9.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:24 Train_loss:3.3226990699768066 Val_loss:2.5256152153015137 Dir Accuracy:f0.5041667222976685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:06<00:00,  9.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:25 Train_loss:3.3107776641845703 Val_loss:2.5187902450561523 Dir Accuracy:f0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:06<00:00,  9.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch:26 Train_loss:3.317934036254883 Val_loss:2.5302281379699707 Dir Accuracy:f0.5041667222976685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 44/60 [00:04<00:01,  9.66it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      8\u001b[0m train_loss_avg \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seq,target,mean,std \u001b[38;5;129;01min\u001b[39;00m tqdm(train_dataloader):\n\u001b[1;32m     10\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     11\u001b[0m     seq \u001b[38;5;241m=\u001b[39m seq\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1316\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:1282\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1282\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1283\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1284\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1123\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/queues.py:116\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py:305\u001b[0m, in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrebuild_storage_fd\u001b[39m(\u001b[38;5;28mcls\u001b[39m, df, size):\n\u001b[0;32m--> 305\u001b[0m     fd \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    307\u001b[0m         storage \u001b[38;5;241m=\u001b[39m storage_from_cache(\u001b[38;5;28mcls\u001b[39m, fd_id(fd))\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/resource_sharer.py:57\u001b[0m, in \u001b[0;36mDupFd.detach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetach\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     56\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Get the fd.  This should only be called once.'''\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_resource_sharer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reduction\u001b[38;5;241m.\u001b[39mrecv_handle(conn)\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/resource_sharer.py:87\u001b[0m, in \u001b[0;36m_ResourceSharer.get_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[1;32m     86\u001b[0m address, key \u001b[38;5;241m=\u001b[39m ident\n\u001b[0;32m---> 87\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauthkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m c\u001b[38;5;241m.\u001b[39msend((key, os\u001b[38;5;241m.\u001b[39mgetpid()))\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py:508\u001b[0m, in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthkey should be a byte string\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m authkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 508\u001b[0m     \u001b[43manswer_challenge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m     deliver_challenge(c, authkey)\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py:757\u001b[0m, in \u001b[0;36manswer_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    755\u001b[0m digest \u001b[38;5;241m=\u001b[39m hmac\u001b[38;5;241m.\u001b[39mnew(authkey, message, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmd5\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdigest()\n\u001b[1;32m    756\u001b[0m connection\u001b[38;5;241m.\u001b[39msend_bytes(digest)\n\u001b[0;32m--> 757\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m        \u001b[38;5;66;03m# reject large message\u001b[39;00m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;241m!=\u001b[39m WELCOME:\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AuthenticationError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdigest sent was rejected\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py:216\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative maxlength\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 216\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bad_message_length()\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py:414\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 414\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py:379\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 379\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss_avg = 100\n",
    "loss_test = 100\n",
    "avg_dir_accuracy = 0 \n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss_avg = 0\n",
    "    for seq,target,mean,std in tqdm(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        seq = seq.cuda()\n",
    "        predictions = model(seq)\n",
    "        loss = criterion(predictions, target.cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_avg += loss / len(train_dataloader)\n",
    "\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        with torch.no_grad():\n",
    "            loss_test = 0\n",
    "            avg_dir_accuracy = 0\n",
    "            for data in val_dataloader:\n",
    "                seq,target,mean,std = data\n",
    "                predictions = model(seq.cuda())\n",
    "                # validation loss\n",
    "                batch_loss = criterion(predictions, target.cuda())\n",
    "                loss_test += batch_loss\n",
    "                tst = dir_acc(seq.cuda(),target.cuda(),predictions)\n",
    "                # print('tst',tst)\n",
    "                avg_dir_accuracy += dir_acc(seq.cuda(),target.cuda(),predictions)\n",
    "            loss_test /= len(val_dataloader)\n",
    "            avg_dir_accuracy /= len(val_dataloader)\n",
    "    print ('-'*15 + f'Epoch:{epoch} Train_loss:{train_loss_avg} Val_loss:{loss_test} Dir Accuracy:f{avg_dir_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
